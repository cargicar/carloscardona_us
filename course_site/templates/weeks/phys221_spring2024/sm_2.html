{% load static %}
<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>SM_2</title>

    <!-- Bootstrap Core CSS -->
    <link href="{% static 'vendor/bootstrap/css/bootstrap.min.css' %}" rel="stylesheet">

    <!-- Theme CSS -->
    <link href="{% static 'css/clean-blog.min.css' %}" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="{% static 'vendor/font-awesome/css/font-awesome.min.css' %}" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- MathJAx -->
    <script>
     MathJax = {
         tex: {
             inlineMath: [['$', '$'], ['\\(', '\\)']]
         }

     };
    </script>
    <script id="MathJax-script" async
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>

</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    Menu <i class="fa fa-bars"></i>
                </button>
                <img src= "{% static 'img/cwru-logo.png' %}" alt="cwru-logo" width="100" height="100">
                <header class="intro-header" style="background-image: url({% static 'img/cwru-logo.png' %})">
                <!-- <a class="navbar-brand" href="">Home</a> -->
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header class="intro-header" style="background-image: url({% static 'img/gas1.gif' %})">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                  <div class="site-heading">
		    <br><br><br><br>
                        <h1  style="color:black;" >Statistical Mechanics 2 </h1>
                        <hr class="small">
                        <h2  style="color:black;">The Boltzmann Distribution</h2>
                        <h3  style="color:black;">PHYS-221 April 19 / 2024 </h3>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Main Content -->
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
              <div class="post-preview">
		
		                     		  <h2>Learning Objectives</h2>

		  <ol>
		    <li>Learn the Boltzmann Distribution </li> 
		  </ol>
		  <br><br>
		  <b>Fill in the blanks</b>:<br>
		  A macrostate corresponds to many different _______________.<br>
		  <br>
		  The equilibrium macrostate is the one with the largest __________.<br><br>
		  The entropy of a system is maximized by the ___________ state.<br><br>
	What is temperature? ________________<br><br>		  
	<h3>Entropy and Temperature</h3>

	<em> Temperature is a  measured of the average kinetic energy of the vibrating and colliding atoms making up a substance.</em><br><br> 
        Let's once again use our intuition to define a useful quantity. Imagine again a gas in a box splited in half, this time by a membrane that allows to transfer energy from one side to the other by collisions of particles on the membrane.  If one portion of the gas is heated, we expect the temperature of such side (as measure by a thermometer) to rise: <em> Heat is defined as the transfer of energy across the boundary of a system due to a temperature difference between the system and its surroundings</em>. <br><br>
	From the microscopic point of view, this increase in temperature is due to the increase of the overall kinetic energy of the constituent particles. If left alone, particles hitting the membrane will transfer part of its kinetic energy to the some particles at the other side, until we reach the equilibrium of the whole system. By the Second Law, this new equilibium state must have a higher entropy that the previous equilibrium state, and since the new state is an equilibrium state, the temperature of both sides must be the same now and the entropy should have increased.<br><br>
                    With this intuitive picture in mind, the heat transfer, or energy transferred from one side of the box to the other, produce a change of entropy from the previous state to the new equilibrium state at temperature $T$,  $$\Delta Q=T\Delta S. $$ With this definition, we can compute changes in entropy by knowing the amount of energy transfered in form of heat,
                    $$\Delta S=\int_i^f{dQ\over T}. $$

	<h2> The Boltzmann Distribution.</h2>

	                    <h3>Distributing Energy</h3>
Now we will start moving towards Quantum Statistical Mechanics. Let's come back to our gas in a box example, but now let's give some quantum structure to the  particles in the box.  For example, let's consider each particle in the gas as being a small quantum harmonic oscilator, say two atoms tied by a $-\kappa x^2$ force.
                   <br><br>
                   <center>   <img src="{% static "img/gas1.gif" %}" width="400"></center><br><br>
                   Each atom can be at any of the energy states allowed by the quantum harmonic oscilator, i.e,
                   $$E^0_n=\left(n_i+{1\over2}\right)\hbar\omega $$ for convenience, let's measure each of these energies with respect to the ground state energy,
                   $$\boxed{E_n=E^0_n- {1\over2}\hbar\omega=n_i\hbar\omega\,.}$$
                   The total quantum internal energy is given by
                   $$\boxed{ E_T=\sum_{i=1}^Nn_i\hbar\omega\equiv M\hbar\omega} $$ where $N$ is the total number of harmonic oscilators and $M$ is the sum over all quantum numbers for the energy, or $\sum_{i=1}^Nn_i=M$.<br><br>
                   Our goal is to find the probability that a particle (an harmonic oscilator) in the gas, be in a state of energy $E_n$. First it is useful to answer the question, in how many ways $N-$integers ($N-$particles quantum numbers) can be added to give the integer $M$?, the answer is
                   $$\begin{pmatrix}M+N-1 \\ M\end{pmatrix}={(M+N-1)!\over M!(N-1)!}\,. $$
This is in turn would be the total number of ways the energy could be distributed among the $N$ quantum numbers.
                   <hr>
                   <hr>
                   Using the basic definition of probability, the probability that a particle $i$ will possess energy $E_{n_i}$, or equivalently, quantum number $n_i$ is,<br><br>:
                   <center>P(n_i)=(Number of ways to have energy $n_i$)/(Total number of ways energy can be distributed)</center>
                   $$P_{n_i}=\frac{((M-n_i)+(N-2))!\over (M-n_i)!(N-2)!} {(M+N-1)\over M!(N-1)!}$$
                   Let's plot this function on a notebook:
                   <center>   <img src="{% static "img/pn.png" %}" width="800"></center><br><br>
                   The most probable state for a given particle, or the state in which the number of ways of distributing the energy among all particles is greatest, is one of lower energy.<br><br>
		   <h2>"General Derivation"</h2>
                   Let us try a more general derivation. We need to maximize the entropy of the system subject to the constraint that the total energy and total number of particles are both fixed:
		   
                   $$Max(\log W),\quad\sum_i n_i=N,\qquad \sum_i\epsilon_in_i=E\,. $$
		   <br>
		   Are you familiar with Lagrage multipliers? 

		   <ol  style="line-height:300%" type="A">
		   <img src="{% static "img/iclicker.png" %}" width="100"> <br>
		 <!-- longer -->
		   <li> Yes</li>
		   <li> No</li>
		 
		    <li> Maybe</li>

				</ol>
	<br><br>


		   
                   Using  <a href="https://en.wikipedia.org/wiki/Lagrange_multiplier" target= "_blank"  style="color:blue;"> lagrange multipliers</a>, we are looking for  the maximum of,

                   $$ \Phi(n_i)=\log W+\alpha_1 (\sum_i n_i-N)+\alpha_2(\sum_i\epsilon_in_i-E)\,.$$

        <br><br>
	In general, of we have a system of $N$ particles, with $n_i$ particles at energy $\epsilon_i$, the number of micro-states is given by,
	$$ W= {N!\over n_1!n_2!n_3!...}\,,$$
	Then we can write,
	                   $$ \Phi(n_i)=\log N!-\sum_i\log n_i!+\alpha_1 (\sum_i n_i-N)+\alpha_2(\sum_i\epsilon_in_i-E)\,$$
        Using the Stirling approximation,
	$$\log n_i!\sim n_i\log n_i\,,$$
	and ignoring irrelevant constants,
	 $$ \Phi(n_i)\sim- \sum_{i}n_i\log n_i+\alpha_1 (\sum_i n_i-N)+\alpha_2(\sum_i\epsilon_in_i-E)\,$$
<br><br>
Now we can find the maximum. What is the value of $n^{(0)}_i$ that maximizes $\Phi(n_i)$

		   <ol  style="line-height:300%" type="A">
		   <img src="{% static "img/iclicker.png" %}" width="100"> <br>
		 <!-- longer -->
		   <li>$ \log n_i=(\alpha_1-1)+\alpha_2$ </li>
		   <li>$ \log n_i=(\alpha_1-1)+\alpha_2 \epsilon_i$</li>
		 		   <li> $\log n_i=\alpha_1 $</li>
		 		   <li> None of the above </li>

				</ol>
	<br><br>
Then we get:

                   $$ n_i = e^{\alpha-1}\,e^{-\beta E_i}=A\,e^{-\beta E_i} $$

                   which is the Boltzmann distribution.

                   Thus, the Boltzmann distribution is the probability distribution that maximizes the entropy of a system of particles in thermal equilibrium subject to the constraint that the total energy of the system is fixed. It describes the distribution of particles in energy levels and is widely used in statistical mechanics to model the behavior of particles in gases, liquids, and solids.

		   <br><br>
The result is shockingly quite universal: for large systems of distinguishable particles at temperature $T$, the probability of an individual particle to be at state $n$ with energy $E_n$ is given by the Boltzmann distribution,
                   $$\boxed{P(E_n)=A\,e^{-E_n\over k_B T}\,,}$$
                   Where the index $n$ stands for the set of all quantum numbers specifying an individual particle energy, and the proportionality constant $A$ is determined by imposing the normalization condition
                   $$\sum P(E_n)=1=\sum_n A\,e^{-E_n\over k_B T} $$ or
                   $$A={1\over\sum_ne^{-E_n\over k_B T}}\,. $$
                   In other words, the Boltzman distribution is given by,
                   $$\boxed{P(E_n)={e^{-E_n\over k_B T}\over \sum_n A\,e^{-E_n\over k_B T} }\,.}$$ 
                   <center> <img src="{% static "img/pnvsbol.png" %}" width="800"></center><br><br>

                   <hr>
                    <b> Example</b>: Consider a gas with $N=10^{23}$ molecules. Initially, the gas is contained in one half of a box, but eventually it is allowed to fill the remaining half. Compute the change of entropy using both formulas for $\Delta S$ we have seen, i,e, by counting the number of microstates, and by heat transfer.
                    <hr>

                    <hr>
<!--                     <b> Example</b>: Consider a gas with $N=10^{23}$ molecules. Initially, the gas is contained in one half of a box, but eventually it is allowed to fill the remaining half. Compute the change of entropy using both formulas for $\Delta S$ we have seen, i,e, by counting the number of microstates, and by heat transfer. -->
<!--                     <hr> -->
<!--                     <br><br><br> -->
<!--                     <br><br><br> -->

<!-- <br><br>		      -->
<!--  <h2>Problem 9.23</h2>	   -->
<!-- The entropy of an ideal monatomic gas is $(3/2)N\,k_B \ln E + N\,k_B \ln V - N\,k_B \ln N$, to within an additive constant. -->
<!-- Show that this implies the correct relationship between internal energy E and temperature. -->
<!-- <br>   		  -->
<!-- 				  <b> Pair up and work on it</b>. -->
				 
<!-- 				  <iframe width="560" height="315" src="https://www.youtube.com/embed/iHdviZkM7S4?si=P7COxfkgZMfCxZ-M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> -->
<!-- 		 <br><br><br><br> -->
<!-- 		 <h2>Problem 9.27</h2> -->
<!-- Four distinguishable harmonic oscillators $a, b, c$, and $d$ may exchange energy. The energies allowed for particle $a$ are -->
<!-- 		 $E_a=n_a\hbar\omega_0$ and so on. -->
<!-- 		 Consider an overall state (macrostate) in which -->
<!-- the total energy is $3\hbar\omega_0$. One possible microstate would have particles a, b, and c in their $n=0$ states and particle d in its $n = 3$ state; that is, $(n_a, n_b, n_c, n_d) = (0, 0, 0, 3)$. -->
<!--  <ol type="A">  -->
<!-- 		   <li>  List all possible microstates.</li> -->
<!-- 		   <li>  What is the probability -->
<!-- 		     that a given particle will be in its $n= 0$ state?</li> -->
<!-- 		   <li> Answer part (b) for all other possible values of $n$.</li> -->
<!-- 		   <li> Plot the probability versus $n$.</li></ol> -->

<!-- <br>   		  -->
<!-- 				  <b> Pair up and work on it</b>. -->
				 
<!-- 				  <iframe width="560" height="315" src="https://www.youtube.com/embed/iHdviZkM7S4?si=P7COxfkgZMfCxZ-M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> -->
<!-- 				  <br><br><br><br> -->
				  
<!--  <ol type="A">  -->
<!--    <li>  (3,0,0,0), (0,3,0,0), (0,0,3,0), (0,0,0,3),<br> -->
<!--      (2,1,0,0), (2,0,1,0), (2,0,0,1),<br> (1,2,0,0), (1,0,2,0), (1,0,0,2),<br> -->
<!--      (0,2,1,0), (0,2,0,1), (0,1,2,0), (0,1,0,2), (0,0,2,1), (0,0,1,2),<br> -->
<!--      (1,1,1,0), (1,1,0,1), (1,0,1,1), (0,1,1,1).</li> -->
<!--    <li> $n = 0$ appears 10 times out of a total of 20 quantum numbers, for a probability of 0.5.</li> -->
<!-- 		   <li> $n = 1$ appears 6 times; 6/20 = 0.3. $n = 2$ appears 3 times; 3/20 = 0.15. $n = 3$ appears 1 time; 1/20 = 0.05.</li> -->
<!-- 		   <li> Plot the probability versus $n$.</li></ol> -->

<!-- <br><br>   		  -->
<!--                   <h2> Problem A.</h2> -->
<!-- 		  Consider a gas with $N=10^{23}$  molecules. Initially, the gas is contained in one half of a box, but eventually it is allowed to fill the remaining half. -->
<!-- <ol> -->
<!--   <li> Compute the change of entropy by counting the number of micro-states.</li> -->

<!--   <li> Use the Stirling Approximation Links to an external site. to rewrite the computation above for very large N </li> -->

<!--   <li> Compute the change of entropy again, but now use the heat transfer formula.</li> -->
 
<!--   <br> -->

<!-- 				  <b> Pair up and work on it</b>. -->
				 
<!-- 				  <iframe width="560" height="315" src="https://www.youtube.com/embed/iHdviZkM7S4?si=P7COxfkgZMfCxZ-M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> -->


			<br><br><br>
                </div>
            </div>
        </div>
    </div>


</body>

</html>
